{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837563ad-87d1-4c15-9fe9-543d2db817a8",
   "metadata": {},
   "source": [
    "## Project Question Answering SQUAD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96a8d4-2ea9-4c6e-b1ff-fc56aeff35de",
   "metadata": {},
   "source": [
    "Terminologi Question Answering (QA) dalam Kecerdasan Buatan mengacu pada kemampuan mesin untuk merespons pertanyaan yang diajukan dalam natural languange atau bahasa manusia. Tujuan utama dari teknologi ini adalah untuk mengekstrak informasi yang relevan dari sejumlah besar data dan menyajikannya dalam bentuk jawaban yang ringkas. Para peneliti dan insinyur AI telah mengembangkan model khusus untuk memenuhi tujuan tersebut. \n",
    "Model ini menerima pertanyaan dan kemudian memproses data teks untuk menentukan jawaban yang paling akurat. Misalnya, jika pertanyaannya adalah \"Apa puncak gunung tertinggi di dunia?\" model QA akan memindai databasenya dan memberikan jawaban \"Gunung Everest\".\n",
    "Tujuan akhir dari model Question Answering adalah untuk benar-benar memahami makna dibalik pertanyaan dan memberikan jawaban yang relevan dan sesuai dengan konteksnya. Keberhasilan model QA diukur dari kemampuannya memberikan jawaban yang akurat dan bermakna terhadap berbagai pertanyaan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd83d5-fdd7-4eb6-bd0c-8da6bf5704d2",
   "metadata": {},
   "source": [
    "## 1. Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1b0e7a-7275-476f-989f-3fc6e25a0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b857d6f-7fe0-4e1d-b0b7-8778248f7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\\\Users\\\\PPL2\\\\Documents\\\\Private\\\\Model\\\\Pacman Data Science\\\\Project\\\\Natural Languange Processing'\n",
    "# /kaggle/input/train-v1.1.json\n",
    "# /kaggle/input/dev-v1.1.json\n",
    "train_data = pd.read_json(r'C:\\\\Users\\\\PPL2\\\\Documents\\\\Private\\\\Model\\\\Pacman Data Science\\\\Project\\\\Natural Languange Processing/train-v1.1.json')\n",
    "validation_data = pd.read_json(r'C:\\\\Users\\\\PPL2\\\\Documents\\\\Private\\\\Model\\\\Pacman Data Science\\\\Project\\\\Natural Languange Processing/dev-v1.1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a93ddb3-5fda-401f-b04a-3ad3f3dd3ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'University_of_Notre_Dame', 'paragra...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Montana', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'Genocide', 'paragraphs': [{'context...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'Antibiotics', 'paragraphs': [{'cont...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  version\n",
       "0  {'title': 'University_of_Notre_Dame', 'paragra...      1.1\n",
       "1  {'title': 'Beyoncé', 'paragraphs': [{'context'...      1.1\n",
       "2  {'title': 'Montana', 'paragraphs': [{'context'...      1.1\n",
       "3  {'title': 'Genocide', 'paragraphs': [{'context...      1.1\n",
       "4  {'title': 'Antibiotics', 'paragraphs': [{'cont...      1.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b52b4551-4c1f-44d2-8452-e7f6da233522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_tokenizer(data):\n",
    "    \"\"\"\n",
    "        This function takes a DataFrame containing data structured as raw SQuAD\n",
    "        (Stanford Question Answering Dataset) data and reorganizes it to align\n",
    "        with BERT tokenizer requirements.\n",
    "        \n",
    "        It returns a dictionary with the following structure:\n",
    "        return dict({\n",
    "            'id': [list of question ids],\n",
    "            'title': [list of titles],\n",
    "            'context': [list of contexts],\n",
    "            'question': [list of questions],\n",
    "            'answers': [list of { # in squard1 every question has only 1 answer\n",
    "                'answer_start': [list of indicies where answer start in the context]\n",
    "                'text': [list of answers texts]\n",
    "            \n",
    "            }]\n",
    "        })\n",
    "    \n",
    "    Parameters:\n",
    "    - data (DataFrame): Input DataFrame with raw SQuAD data.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Cleaned and reorganized DataFrame following the specified structure for BERT tokenizer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # intialize of empty lists aligning with BERT tokenizer structure\n",
    "    ids = []\n",
    "    titles = []\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    # iterate over documents of the dataframe\n",
    "    for idx, qa_doc in data.iterrows():\n",
    "        # we grab the first column which contain the actuall data\n",
    "        document = qa_doc[0]\n",
    "        # grab document tilte\n",
    "        qa_title = document['title']\n",
    "        # grab list of paragraphs associated with that title\n",
    "        paragraphs = document['paragraphs']\n",
    "        \n",
    "        # for each paragraph extract context, questions and answers\n",
    "        for parg in paragraphs:\n",
    "            parg_context = parg['context']\n",
    "            parg_questions = parg['qas']\n",
    "            parg_questions_len = len(parg_questions)\n",
    "            \n",
    "            for p_question in parg_questions:\n",
    "                qa_id = p_question['id']\n",
    "                question = p_question['question']\n",
    "                q_answers = p_question['answers'][0]\n",
    "                answer = {\n",
    "                    'answer_start': [q_answers['answer_start']],\n",
    "                    'text': [q_answers['text']]\n",
    "                }\n",
    "                \n",
    "                # add the extracted data to corresponding list\n",
    "                ids.append(qa_id)\n",
    "                titles.append(qa_title)\n",
    "                contexts.append(parg_context)\n",
    "                questions.append(question)\n",
    "                answers.append(answer)\n",
    "    \n",
    "    # final structure of re-organized data\n",
    "    cleaned_data = {\n",
    "        'id': ids,\n",
    "        'title': titles,\n",
    "        'context': contexts,\n",
    "        'question': questions,\n",
    "        'answers': answers\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ee8a53-e9d6-4e26-912b-c6506df8bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PPL2\\AppData\\Local\\Temp\\ipykernel_15788\\165066262.py:37: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  document = qa_doc[0]\n"
     ]
    }
   ],
   "source": [
    "# restructure our data to align with BERT tokenizer\n",
    "train_data = prepare_data_for_tokenizer(train_data)\n",
    "validation_data = prepare_data_for_tokenizer(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd524ef6-4f80-40e1-b5a3-7dcd0922fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "# put our train and validation in dataset object\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_data),\n",
    "    'validation': Dataset.from_pandas(validation_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3381da42-da4e-4025-8e37-2b36d7c590f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['5733be284776f41900661182', '5733be284776f4190066117f'],\n",
       " 'title': ['University_of_Notre_Dame', 'University_of_Notre_Dame'],\n",
       " 'context': ['Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       "  'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'],\n",
       " 'question': ['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       "  'What is in front of the Notre Dame Main Building?'],\n",
       " 'answers': [{'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
       "  {'answer_start': [188], 'text': ['a copper statue of Christ']}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect new data shape as intended\n",
    "dataset['train'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074544ae-16d8-4ab8-8b91-e841de1a0643",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e2ed8-944d-4d51-869c-5caa62c0e426",
   "metadata": {},
   "source": [
    "Sebelum kita bisa mengirimkan teks model, perlu dilakukan preprocessing. Hal ini dilakukan oleh Transformers Tokenizer yang akan melakukan tokenisasi dari input\n",
    "\n",
    "    Mengkonversi token ke ID yang bersesuaian dalam kamus pretrained\n",
    "    memasukkan secara proper token khusus untuk membentuk kalimat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15facce2-4eea-43e3-874f-9d49c87ac3d3",
   "metadata": {},
   "source": [
    "Representasi tokenizer dilakukan dengan  AutoTokenizer.from_pretrained method untuk memastikan :\n",
    "\n",
    "mengunduh kosakata yang digunakan didownload dan di-cache, sehingga tidak diunduh lagi saat berikutnya menjalankan sel tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45bcb342-4625-4c25-93df-40da86fcb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint = \"distilbert-base-cased-distilled-squad\" # this is the pretrained model that was fine tuned\n",
    "\n",
    "# This check point for model after fine tuned on qa tasks\n",
    "model_checkpoint = \"Ahmed-Zakaria/distilbert-base-cased-finetuned-squad\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660d2392-6b95-4b30-b381-835e4e4ae088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7684458e-f61c-487e-888f-edd9ec0d0f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1327, 1110, 1240, 139, 9637, 1942, 136, 102, 139, 9637, 1942, 1110, 139, 2386, 5817, 17264, 13832, 13775, 1197, 20777, 4894, 20936, 1116, 1121, 25267, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test our tokenizer\n",
    "tokenizer(\"What is your BERT?\", \"BERT is Bidirectional Encoder Representations from Transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd626bd-6115-4108-bb08-59d5bdd90b43",
   "metadata": {},
   "source": [
    "Tokenizer akan mengambil pertanyaan dan memasangkan satu sama lain dengan [SEP] special token untuk menyerupai [CLS] pertanyaan [SEP] konteks [SEP] akan digunakan max_length parameter untuk menangani input yang panjang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd09bc3-6064-4c22-b094-15be1f32effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384  # The maximum length of a feature (question + context)\n",
    "doc_stride = 128  # The allowed overlap between two part of the context when splitting is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50125f06-1412-4529-97eb-7b02f24262cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see that in practive\n",
    "example = dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0284510b-75f8-4f20-bf52-1182ec0d1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b03692cd-bdc7-48e5-94f7-2857ffea9d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokenized input before truncation: 181\n"
     ]
    }
   ],
   "source": [
    "# before truncating the input\n",
    "print(\"length of tokenized input before truncation:\", len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98857bd-ccf7-4cbc-86a4-2f9f89e46406",
   "metadata": {},
   "source": [
    "If we use truncation we lose 76 tokens of the original input which is not ideal\n",
    "\n",
    "Note that we never want to truncate the question, only the context, and so we use the only_second truncation method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6391daed-a5b7-49f9-ba4d-9d6d9c8a189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokenized input after truncation: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"length of tokenized input after truncation:\",\n",
    "      len(\n",
    "        tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        max_length=100,\n",
    "        truncation=\"only_second\",\n",
    "    )[\"input_ids\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44000aac-8f35-4563-b5e4-c0309cc8b4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our example is \n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8945103-d0bf-4ef3-95b7-3cf00a8b8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using max length lower than the input length with return_flowing_tokens set to true\n",
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9582dc09-33b7-4b9f-99c9-3eeacc422b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mapping = tokenized_example[\"overflow_to_sample_mapping\"]\n",
    "sample_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffe53fd3-b296-4cf5-ba96-76b167c520e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 (Original Example 0): [101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 102]\n",
      "\n",
      "Feature 2 (Original Example 0): [101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 102]\n",
      "\n",
      "Feature 3 (Original Example 0): [101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 102]\n",
      "\n",
      "Feature 4 (Original Example 0): [101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenized input of features\n",
    "for i, feature in enumerate(tokenized_example[\"input_ids\"]):\n",
    "    original_example_index = sample_mapping[i]\n",
    "    print(f\"Feature {i + 1} (Original Example {original_example_index}): {feature}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "533a6cd6-3f9f-4094-bf91-e61b9f1a3c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 (Original Example 0): [CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]\n",
      "\n",
      "Feature 2 (Original Example 0): [CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]\n",
      "\n",
      "Feature 3 (Original Example 0): [CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]\n",
      "\n",
      "Feature 4 (Original Example 0): [CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, feature in enumerate(tokenized_example[\"input_ids\"]):\n",
    "    original_example_index = sample_mapping[i]\n",
    "    print(f\"Feature {i + 1} (Original Example {original_example_index}): {tokenizer.decode(feature)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10019e5d-4c3b-4c9b-95b2-a2753bf725f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 offset_mapping (Original Example 0): [(0, 0), (0, 2), (3, 7), (8, 11), (12, 15), (16, 22), (23, 27), (28, 37), (38, 44), (45, 47), (48, 52), (53, 55), (56, 59), (59, 63), (64, 70), (70, 71), (0, 0), (0, 13), (13, 15), (15, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 52), (52, 53), (54, 56), (56, 58), (59, 62), (63, 67), (68, 76), (76, 77), (77, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 126), (126, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (0, 0)]\n",
      "\n",
      "Feature 2 offset_mapping (Original Example 0): [(0, 0), (0, 2), (3, 7), (8, 11), (12, 15), (16, 22), (23, 27), (28, 37), (38, 44), (45, 47), (48, 52), (53, 55), (56, 59), (59, 63), (64, 70), (70, 71), (0, 0), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (0, 0)]\n",
      "\n",
      "Feature 3 offset_mapping (Original Example 0): [(0, 0), (0, 2), (3, 7), (8, 11), (12, 15), (16, 22), (23, 27), (28, 37), (38, 44), (45, 47), (48, 52), (53, 55), (56, 59), (59, 63), (64, 70), (70, 71), (0, 0), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (0, 0)]\n",
      "\n",
      "Feature 4 offset_mapping (Original Example 0): [(0, 0), (0, 2), (3, 7), (8, 11), (12, 15), (16, 22), (23, 27), (28, 37), (38, 44), (45, 47), (48, 52), (53, 55), (56, 59), (59, 63), (64, 70), (70, 71), (0, 0), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (674, 679), (680, 686), (687, 689), (690, 694), (694, 695), (0, 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspecting sample offset mapping\n",
    "for i, offset_map in enumerate(tokenized_example[\"offset_mapping\"]):\n",
    "    original_example_index = sample_mapping[i]\n",
    "    print(f\"Feature {i + 1} offset_mapping (Original Example {original_example_index}): {offset_map}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92695f34-0f6f-4917-9cf1-6b26ec2ec8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To To\n"
     ]
    }
   ],
   "source": [
    "# check if our token index is set correctly\n",
    "first_token_id = tokenized_example[\"input_ids\"][0][1]\n",
    "offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
    "print(\n",
    "    tokenizer.convert_ids_to_tokens([first_token_id])[0],\n",
    "    example[\"question\"][offsets[0] : offsets[1]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b562a23-cadd-4983-b24b-4b6df4cb5a2e",
   "metadata": {},
   "source": [
    "Untuk memasangkan pertanyaan dengan konteks dan membentuk fitur, kita perlu untuk membedakan bagian dari fitur yang akan berkorespondensi dengan pertanyaan dan bagian mana yang berkorespondensi dengan konteks. Ini adalah part di mana sequence_ids dari tokenized_example akan berfungsi.\n",
    "\n",
    "    0 indikasi pertanyaan\n",
    "    1 indikasi konteks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2547118c-4026-4fba-a383-19911e5cb541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "# sequence_ids keep track of different part of input mapping to either context or question\n",
    "# call sequence_ids() without parameter default for to sequence at index 0\n",
    "# since we are using 1 example here we will not worry about index for now\n",
    "# since we have 4 features in our example we can use 0, 1, 2, 3 index to show mapping for each part\n",
    "\n",
    "# i used feature 3 with index 2 (since we count from 0) because i know where the answer :D\n",
    "sequence_ids = tokenized_example.sequence_ids(2)\n",
    "print(sequence_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361f163-6b90-4ee5-bc86-0a661b058af7",
   "metadata": {},
   "source": [
    "Karena kita akan mengeluarkan probabilitas untuk setiap token yang menunjukkan probabilitas token untuk menjadi token jawaban awal atau akhir, kita memerlukan cara untuk memetakan indeks awal karakter tertentu ke token dalam data yang diberi token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "508761ac-83e8-4b70-b6c6-bccce1df60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anser start position:  72 Answer end position:  78\n"
     ]
    }
   ],
   "source": [
    "# grab the answer for our example and its boundaries\n",
    "answers = example[\"answers\"]\n",
    "answer_start_char = answers[\"answer_start\"][0]\n",
    "answer_end_char = answer_start_char + len(answers[\"text\"][0])\n",
    "\n",
    "# first we define the boundaries of the context in the tokenized data (question + context)\n",
    "context_token_start_index = 0\n",
    "\n",
    "# we trying to get **first** token with value = 1 marking the **start** of context\n",
    "while sequence_ids[context_token_start_index] != 1:\n",
    "    context_token_start_index += 1\n",
    "\n",
    "# we trying to get **last** token with value = 1 marking the **end** of context\n",
    "context_token_end_index = len(tokenized_example[\"input_ids\"][2]) - 1\n",
    "while sequence_ids[context_token_end_index] != 1:\n",
    "    context_token_end_index -= 1\n",
    "\n",
    "# Detect if the answer is in the current feature\n",
    "\n",
    "# first grab offset mapping for the feature (we will use first feature to demonstrate at index [0])\n",
    "# offsets map each token start and end positions in the context\n",
    "offsets = tokenized_example[\"offset_mapping\"][2]\n",
    "\n",
    "# check if answer start char and end char from our data is in current feature span or not\n",
    "# if it is in the context grab the index in current context span\n",
    "if (\n",
    "    # first token at the context start char index\n",
    "    offsets[context_token_start_index][0] <= answer_start_char\n",
    "    # last token at the context last char index\n",
    "    and offsets[context_token_end_index][1] >= answer_end_char\n",
    "):\n",
    "    # Move the context_token_start_index and context_token_end_index to the two ends of the answer.\n",
    "    # we go through each token in the feature and check its offset mapping (where it start and end)\n",
    "    # and compare its offset to answer start index given to us to locate token corresponding to that \n",
    "    # start char index of the answer\n",
    "    while (\n",
    "        context_token_start_index < len(offsets)\n",
    "        and offsets[context_token_start_index][0] <= answer_start_char\n",
    "    ):\n",
    "        context_token_start_index += 1\n",
    "    start_position = context_token_start_index - 1\n",
    "    \n",
    "    while offsets[context_token_end_index][1] >= answer_end_char:\n",
    "        context_token_end_index -= 1\n",
    "    end_position = context_token_end_index + 1\n",
    "    \n",
    "    print(\"Anser start position: \", start_position, \"Answer end position: \", end_position)\n",
    "else:\n",
    "    print(\"The answer is not in this feature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679a317-54b3-4592-bf43-a268ec08d89c",
   "metadata": {},
   "source": [
    "changeing sequence ids to same feature also) you will need to change the following lines of code:\n",
    "\n",
    "    sequence_ids = tokenized_example.sequence_ids(2)\n",
    "    offsets = tokenized_example[\"offset_mapping\"][2]\n",
    "    context_token_end_index = len(tokenized_example[\"input_ids\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57b67d87-ab14-4823-a6b2-782bf5deb65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped answer:  Saint Bernadette Soubirous\n",
      "Actual Answer:  ['Saint Bernadette Soubirous']\n"
     ]
    }
   ],
   "source": [
    "# check the mapping is done correctly\n",
    "print(\"Mapped answer: \", \n",
    "    tokenizer.decode(\n",
    "        # if you tried different indexes make sure to change [2] to match your index\n",
    "        tokenized_example[\"input_ids\"][2][start_position : end_position + 1]\n",
    "    )\n",
    ")\n",
    "print(\"Actual Answer: \", answers[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1074d3f7-3c45-4f9c-a2b4-6095cfabeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    \n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context,\n",
    "    # we need a map from a feature to its corresponding example.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "    # The offset mappings will give us a map from token to character position in the original context.\n",
    "    # This will help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that feature.\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        # One example can give several features, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        \n",
    "        # grab the answer associated with that example\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        \n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            answer_start_char = answers[\"answer_start\"][0]\n",
    "            answer_end_char = answer_start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current feature in the text.\n",
    "            context_token_start_index = 0\n",
    "            while sequence_ids[context_token_start_index] != 1:\n",
    "                context_token_start_index += 1\n",
    "\n",
    "            # End token index of the current feature in the text.\n",
    "            context_token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[context_token_end_index] != 1:\n",
    "                context_token_end_index -= 1\n",
    "                \n",
    "            # Detect if the answer is in feature span.\n",
    "            if (\n",
    "                # first char in the current feature <= answer char start\n",
    "                offsets[context_token_start_index][0] <= answer_start_char\n",
    "                # last char in the current context >= answer char end\n",
    "                and offsets[context_token_end_index][1] >= answer_end_char\n",
    "            ):\n",
    "                # find the token associated with answer start char\n",
    "                while (\n",
    "                    context_token_start_index < len(offsets)\n",
    "                    and offsets[context_token_start_index][0] <= answer_start_char\n",
    "                ):\n",
    "                    context_token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(context_token_start_index - 1)\n",
    "                \n",
    "                # find the token associated with answer end char\n",
    "                while offsets[context_token_end_index][1] >= answer_end_char:\n",
    "                    context_token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(context_token_end_index + 1)\n",
    "\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the cls token index.\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "                \n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "528f6f6d-a8c9-4d31-b7a6-7bf9d9485cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = prepare_train_features(dataset[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b346a19-51ce-46f7-b810-fd65ea82943b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1109, 19349, 1104, 1103, 11373, 1762, 1120, 10360, 8022, 1110, 3148, 1106, 1134, 2401, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1327, 1110, 1103, 144, 10595, 2430, 1120, 10360, 8022, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1327, 7250, 1113, 1499, 1104, 1103, 4304, 4334, 1120, 10360, 8022, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'start_positions': [136, 53, 83, 101, 34], 'end_positions': [142, 57, 85, 107, 40]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adbb0398-cb0a-42dd-beec-03bcf6fe78f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126bc53f69b84d4a8c967bf274483a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df982fc94deb4136bf92ac173865aa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val_set = dataset.map(\n",
    "    prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8441e9d-a6ba-42fd-9fec-6aadb7f741eb",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "Setelah data siap, kita dapat mengunduh pretrained model dan melakukan fine tuning. Untuk case question answering, akan digunakan TFAutoModelForQuestionAnswering class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c746484b-cc07-4e6c-9f35-6071cf3e0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need to run this like if you are using kaggle to run this note book\n",
    "# this line resolve an error which is \"numpy has no attribute called object\" that only appens on kaggle \n",
    "np.object = object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3eb6356-01e0-4886-bf96-758a69077f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae3483220144f4482c68d3694b51f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d30ea57c-eef5-41e2-b415-f5997090297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PPL2\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\PPL2\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFDistilBertForQuestionAnswering were initialized from the model checkpoint at Ahmed-Zakaria/distilbert-base-cased-finetuned-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  65190912  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65192450 (248.69 MB)\n",
      "Trainable params: 65192450 (248.69 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb360b-5a78-4128-8b2f-979631602c55",
   "metadata": {},
   "source": [
    "Parameter default dari model adalah \n",
    "\n",
    "\n",
    "- learning_rate = 2e-5\n",
    "- num_train_epochs = 3\n",
    "- weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72165540-f580-47e2-8acf-87e1ac74ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to tensor flow dataset to ffeed into model\n",
    "train_set = model.prepare_tf_dataset(\n",
    "    train_val_set[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "validation_set = model.prepare_tf_dataset(\n",
    "    train_val_set[\"validation\"],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e402533f-5f06-4fef-8c76-a9e37fe20e3e",
   "metadata": {},
   "source": [
    "## 4. Evaluasi Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b337021-6b97-4f78-8329-8442cab011e3",
   "metadata": {},
   "source": [
    "We masked the start and end logits corresponding to tokens outside of the context to identify them in post processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74dc600b-3663-4a66-aac9-3db14a6398b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples):\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1\n",
    "\n",
    "        # One example can give several features, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        # we set each feature generated from example with the example id it was generated from\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (offset_map if sequence_ids[k] == context_index else None)\n",
    "            for k, offset_map in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31834c6e-7070-44cc-82eb-f1d19e54ea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857802e530264049b94bfc0cfc691a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare our validation data\n",
    "validation_features = dataset[\"validation\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5078e1d9-2668-4436-8755-e9613d50573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert validation data to tensor flow dataset\n",
    "val_set = model.prepare_tf_dataset(\n",
    "     validation_features,\n",
    "     shuffle=False,\n",
    "     batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff214e25-c747-4c67-9e50-c736faaac230",
   "metadata": {},
   "source": [
    "Kita mencari logit score untuk start dan end logits dengan mengecualikan posisi yang menghasilkan:\n",
    "\n",
    "    - Jawaban yang tidak di dalam konteks \n",
    "    - Jawaban dengan panjang negatif \n",
    "    - Jawaban terlalu panjang (dibatasi dengan maksimal panjang = 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a23facea-9784-42a7-b599-ba132e2be9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PPL2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['start_logits', 'end_logits'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(val_set))\n",
    "output = model.predict_on_batch(batch)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c0491d6-d2a8-4402-af7e-04ce1368d5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 384), (16, 384))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.shape, output.end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92cf1d0c-52be-4776-9c07-aba3b61eae08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 46,  57,  78,  54, 118, 108,  72,   9, 108,  45,  73,  41,  80,\n",
       "         91, 157,  35], dtype=int64),\n",
       " array([ 47,  58,  81,  55, 118, 109,  75,  48, 109,  47,  76,  42,  83,\n",
       "         92, 159,  35], dtype=int64))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output.start_logits, -1), np.argmax(output.end_logits, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57234e05-8463-4020-96cd-71b627cc0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 17.9795, 'text': '2015'},\n",
       " {'score': 13.820364, 'text': 'the 2015'},\n",
       " {'score': 12.658412, 'text': '2015 season'},\n",
       " {'score': 11.241871, 'text': '2015 season.'},\n",
       " {'score': 11.125507, 'text': 'for the 2015'},\n",
       " {'score': 10.312961,\n",
       "  'text': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015'},\n",
       " {'score': 9.25402,\n",
       "  'text': '50 was an American football game to determine the champion of the National Football League (NFL) for the 2015'},\n",
       " {'score': 8.499275, 'text': 'the 2015 season'},\n",
       " {'score': 7.5638137, 'text': '2016'},\n",
       " {'score': 7.351606, 'text': 'NFL) for the 2015'},\n",
       " {'score': 7.1056266,\n",
       "  'text': 'champion of the National Football League (NFL) for the 2015'},\n",
       " {'score': 7.082734, 'text': 'the 2015 season.'},\n",
       " {'score': 6.9751983,\n",
       "  'text': 'Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015'},\n",
       " {'score': 6.7369404, 'text': 'National Football League (NFL) for the 2015'},\n",
       " {'score': 6.648327, 'text': 'League (NFL) for the 2015'},\n",
       " {'score': 6.5182, 'text': 'Football League (NFL) for the 2015'},\n",
       " {'score': 5.804418, 'text': 'for the 2015 season'},\n",
       " {'score': 4.9918714,\n",
       "  'text': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season'},\n",
       " {'score': 4.387877, 'text': 'for the 2015 season.'},\n",
       " {'score': 3.932931,\n",
       "  'text': '50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a limit for the answer length\n",
    "max_answer_length = 30\n",
    "n_best_size = 20\n",
    "\n",
    "# grab logits for start and end tokens of the answer\n",
    "start_logits = output.start_logits[15]\n",
    "end_logits = output.end_logits[15]\n",
    "\n",
    "offset_mapping = validation_features[15][\"offset_mapping\"]\n",
    "# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
    "# an example index\n",
    "context = dataset[\"validation\"][15][\"context\"]\n",
    "\n",
    "# Gather the indices the best start/end logits:\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "        # to part of the input_ids that are not in the context.\n",
    "        if (\n",
    "            start_index >= len(offset_mapping)\n",
    "            or end_index >= len(offset_mapping)\n",
    "            or offset_mapping[start_index] is None\n",
    "            or offset_mapping[end_index] is None\n",
    "        ):\n",
    "            continue\n",
    "        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "            continue\n",
    "        if (\n",
    "            start_index <= end_index\n",
    "        ):  # We need to refine that test to check the answer is inside the context\n",
    "            start_char = offset_mapping[start_index][0]\n",
    "            end_char = offset_mapping[end_index][1]\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": context[start_char:end_char],\n",
    "                }\n",
    "            )\n",
    "\n",
    "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[\n",
    "    :n_best_size\n",
    "]\n",
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce6bf8f8-9113-4383-b177-7bcc86457655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "examples = dataset[\"validation\"]\n",
    "features = validation_features\n",
    "\n",
    "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "features_per_example = collections.defaultdict(list)\n",
    "for i, feature in enumerate(features):\n",
    "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771921da-d5a4-4b20-b9ad-c2a461c54108",
   "metadata": {},
   "source": [
    "Bagian terakhir yang harus dikerjakan adalah jawaban yang mustahil (bila squad_v2 = Benar). Kode di atas hanya menyimpan jawaban yang berada di dalam konteks, kita juga perlu mengambil skor untuk jawaban yang tidak mungkin (yang memiliki indeks awal dan akhir yang sesuai dengan indeks token CLS). Ketika satu contoh memberikan beberapa fitur, kita harus memprediksi jawaban yang tidak mungkin ketika semua fitur memberikan skor tinggi pada jawaban yang tidak mungkin (karena satu fitur dapat memprediksi jawaban yang tidak mungkin hanya karena jawabannya tidak sesuai dengan konteksnya)\n",
    "\n",
    "kemudian kita memprediksi jawaban yang tidak mungkin ketika skor tersebut lebih besar dari skor jawaban terbaik yang tidak mungkin. Jika digabungkan bersama-sama, didapatkan fungsi pasca-pemrosesan berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6326cfb3-9cd6-487e-bedd-a4fea321d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def postprocess_qa_predictions(\n",
    "    dataset,\n",
    "    features,\n",
    "    all_start_logits,\n",
    "    all_end_logits,\n",
    "    n_best_size=20,\n",
    "    max_answer_length=30,\n",
    "):\n",
    "    \"\"\"\n",
    "        Takes raw predictions and validate answers by removing answers where start and end positions \n",
    "        are out of context span and return top valid answer\n",
    "        \n",
    "        parameters:\n",
    "            dataset: original dataset to to extract answer text from\n",
    "            features: tokenized dataset\n",
    "            all_start_logits: list of start position probability for each token in each feature\n",
    "            all_end_logits: list of end position probability for each token in each feature\n",
    "            n_best_size: to choose number of valid answers to save\n",
    "            max_answer_length: max length of answer text\n",
    "            \n",
    "        return: dictionary with key = to doc id and value corresponding to best answer\n",
    "            {\n",
    "                'doc_id': best_answer\n",
    "            }\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Build a id -> feature indexes map of doc -> features    \n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        # feature['example_id'] => grab example id feature was generated from\n",
    "        # features_per_doc[...] => append feature id to the key corresponding to their original example id\n",
    "        example_to_features[feature[\"example_id\"]].append(i)\n",
    "\n",
    "    # The dictionaries we have to fill.\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # Logging.\n",
    "    print(\n",
    "        f\"Post-processing {len(dataset)} example predictions split into {len(features)} features.\"\n",
    "    )\n",
    "\n",
    "    # Let's loop over all the docs!\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example['id']\n",
    "        feature_indices = features_per_example[example_id]\n",
    "        \n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[\"context\"]\n",
    "        # Looping through all the features associated to the current document.\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            # We grab the predictions of the model for this feature.\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "            # context.\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            \n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                    # to part of the input_ids that are not in the context.\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or not offset_mapping[start_index]\n",
    "                        or not offset_mapping[end_index]\n",
    "                    ):\n",
    "                        continue\n",
    "                        \n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "                    \n",
    "                    # valid answers\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char:end_char],\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "        best_answer = max(valid_answers, key=lambda x: x[\"score\"])\n",
    "        predictions[example_id] = best_answer[\"text\"]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cde5ad93-78bd-444e-9de0-c68a3df278f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 1747s 3s/step\n"
     ]
    }
   ],
   "source": [
    "raw_predictions = model.predict(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "306935f3-7284-4f7e-8ba4-9660dbd4c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 2911s 4s/step - loss: 1.7272 - end_logits_accuracy: 0.6988 - start_logits_accuracy: 0.6656\n"
     ]
    }
   ],
   "source": [
    "eval_loss = model.evaluate(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac88bf11-c16a-442f-9338-eec296b3ae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 10570 example predictions split into 10822 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cb6cc39c844eaea023187e464e64c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(\n",
    "    dataset[\"validation\"],\n",
    "    validation_features,\n",
    "    raw_predictions[\"start_logits\"],\n",
    "    raw_predictions[\"end_logits\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da5b020c-ee9b-403a-ad69-3aad3464bc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PPL2\\AppData\\Local\\Temp\\ipykernel_15788\\22710840.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad\")\n",
      "C:\\Users\\PPL2\\anaconda3\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for squad contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad/squad.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c204b91-6dc7-4428-b003-a29b245d27f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example ID: 57293e983f37b3190047818d\n",
      "Context: In 2001, 16 national science academies issued a joint statement on climate change. The joint statement was made by the Australian Academy of Science, the Royal Flemish Academy of Belgium for Science and the Arts, the Brazilian Academy of Sciences, the Royal Society of Canada, the Caribbean Academy of Sciences, the Chinese Academy of Sciences, the French Academy of Sciences, the German Academy of Natural Scientists Leopoldina, the Indian National Science Academy, the Indonesian Academy of Sciences, the Royal Irish Academy, Accademia Nazionale dei Lincei (Italy), the Academy of Sciences Malaysia, the Academy Council of the Royal Society of New Zealand, the Royal Swedish Academy of Sciences, and the Royal Society (UK). The statement, also published as an editorial in the journal Science, stated \"we support the [TAR's] conclusion that it is at least 90% certain that temperatures will continue to rise, with average global surface temperature projected to increase by between 1.4 and 5.8 °C above 1990 levels by 2100\". The TAR has also been endorsed by the Canadian Foundation for Climate and Atmospheric Sciences, Canadian Meteorological and Oceanographic Society, and European Geosciences Union (refer to \"Endorsements of the IPCC\").\n",
      "Quesiton Which journal was the joint statement published in?\n",
      "True Answer ['Science'] | Predicted Answer: Science\n",
      "\n",
      "example ID: 57299ec43f37b3190047850e\n",
      "Context: In ring theory, the notion of number is generally replaced with that of ideal. Prime ideals, which generalize prime elements in the sense that the principal ideal generated by a prime element is a prime ideal, are an important tool and object of study in commutative algebra, algebraic number theory and algebraic geometry. The prime ideals of the ring of integers are the ideals (0), (2), (3), (5), (7), (11), … The fundamental theorem of arithmetic generalizes to the Lasker–Noether theorem, which expresses every ideal in a Noetherian commutative ring as an intersection of primary ideals, which are the appropriate generalizations of prime powers.\n",
      "Quesiton What type of ideals generalize prime elements?\n",
      "True Answer ['Prime ideals'] | Predicted Answer: Prime ideals\n",
      "\n",
      "example ID: 56f8b2499b226e1400dd0e3f\n",
      "Context: Luther spoke out against the Jews in Saxony, Brandenburg, and Silesia. Josel of Rosheim, the Jewish spokesman who tried to help the Jews of Saxony in 1537, later blamed their plight on \"that priest whose name was Martin Luther—may his body and soul be bound up in hell!—who wrote and issued many heretical books in which he said that whoever would help the Jews was doomed to perdition.\" Josel asked the city of Strasbourg to forbid the sale of Luther's anti-Jewish works: they refused initially, but did so when a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews. Luther's influence persisted after his death. Throughout the 1580s, riots led to the expulsion of Jews from several German Lutheran states.\n",
      "Quesiton When did riots cause the expulsion of Jews from several German states?\n",
      "True Answer ['Throughout the 1580s'] | Predicted Answer: 1580s\n",
      "\n",
      "example ID: 571ccc00dd7acb1400e4c15a\n",
      "Context: The unusually high concentration of oxygen gas on Earth is the result of the oxygen cycle. This biogeochemical cycle describes the movement of oxygen within and between its three main reservoirs on Earth: the atmosphere, the biosphere, and the lithosphere. The main driving factor of the oxygen cycle is photosynthesis, which is responsible for modern Earth's atmosphere. Photosynthesis releases oxygen into the atmosphere, while respiration and decay remove it from the atmosphere. In the present equilibrium, production and consumption occur at the same rate of roughly 1/2000th of the entire atmospheric oxygen per year.\n",
      "Quesiton What produces the high levels of oxygen on Earth?\n",
      "True Answer ['oxygen cycle'] | Predicted Answer: oxygen cycle\n",
      "\n",
      "example ID: 56f84b68aef2371900625faa\n",
      "Context: Luther next set about reversing or modifying the new church practices. By working alongside the authorities to restore public order, he signalled his reinvention as a conservative force within the Reformation. After banishing the Zwickau prophets, he now faced a battle against not only the established Church but also the radical reformers who threatened the new order by fomenting social unrest and violence.\n",
      "Quesiton What did the radical reformers cause in the new order?\n",
      "True Answer ['unrest and violence.'] | Predicted Answer: social unrest and violence\n",
      "\n",
      "example ID: 5727f746ff5b5019007d9961\n",
      "Context: Doctor Who finally returned with the episode \"Rose\" on BBC One on 26 March 2005. There have since been nine further series in 2006–2008 and 2010–2015, and Christmas Day specials every year since 2005. No full series was filmed in 2009, although four additional specials starring David Tennant were made. In 2010, Steven Moffat replaced Davies as head writer and executive producer. In January 2016, Moffat announced that he would step down after the 2017 finale, to be replaced by Chris Chibnall in 2018. In addition, Series 10 will debut in Spring 2017, with a Christmas special broadcast in 2016.\n",
      "Quesiton What year did Doctor Who finally return to television?\n",
      "True Answer ['2005'] | Predicted Answer: 2005\n",
      "\n",
      "example ID: 573408ef4776f41900661757\n",
      "Context: The war in North America officially ended with the signing of the Treaty of Paris on 10 February 1763, and war in the European theatre of the Seven Years' War was settled by the Treaty of Hubertusburg on 15 February 1763. The British offered France the choice of surrendering either its continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique, which had been occupied by the British. France chose to cede the former, but was able to negotiate the retention of Saint Pierre and Miquelon, two small islands in the Gulf of St. Lawrence, along with fishing rights in the area. They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent. The contemporaneous French philosopher Voltaire referred to Canada disparagingly as nothing more than a few acres of snow. The British, for their part, were happy to take New France, as defence of their North American colonies would no longer be an issue and also because they already had ample places from which to obtain sugar. Spain, which traded Florida to Britain to regain Cuba, also gained Louisiana, including New Orleans, from France in compensation for its losses. Great Britain and Spain also agreed that navigation on the Mississippi River was to be open to vessels of all nations.\n",
      "Quesiton When did the North American French and Indian War end?\n",
      "True Answer ['signing of the Treaty of Paris on 10 February 1763'] | Predicted Answer: 10 February 1763\n",
      "\n",
      "example ID: 56bec0dd3aeaaa14008c9357\n",
      "Context: In the United States, the game was televised by CBS, as part of a cycle between the three main broadcast television partners of the NFL. The network's lead broadcast team of Jim Nantz and Phil Simms called the contest, with Tracy Wolfson and Evan Washburn on the sidelines. CBS introduced new features during the telecast, including pylon cameras and microphones along with EyeVision 360—an array of 36 cameras along the upper deck that can be used to provide a 360-degree view of plays and \"bullet time\" effects. (An earlier version of EyeVision was last used in Super Bowl XXXV; for Super Bowl 50, the cameras were upgraded to 5K resolution.)\n",
      "Quesiton On what television station could an American viewer watch the game?\n",
      "True Answer ['CBS'] | Predicted Answer: CBS\n",
      "\n",
      "example ID: 57275409708984140094dc36\n",
      "Context: In the final years of the apartheid era, parents at white government schools were given the option to convert to a \"semi-private\" form called Model C, and many of these schools changed their admissions policies to accept children of other races. Following the transition to democracy, the legal form of \"Model C\" was abolished, however, the term continues to be used to describe government schools formerly reserved for white children.. These schools tend to produce better academic results than government schools formerly reserved for other race groups . Former \"Model C\" schools are not private schools, as they are state-controlled. All schools in South Africa (including both independent schools and public schools) have the right to set compulsory school fees, and formerly model C schools tend to set much higher school fees than other public schools.\n",
      "Quesiton How do academic results in former Model C schools compare to other schools?\n",
      "True Answer ['better'] | Predicted Answer: better\n",
      "\n",
      "example ID: 56e11044e3433e1400422b78\n",
      "Context: During the period in which the negotiations were being conducted, Tesla said that efforts had been made to steal the invention. His room had been entered and his papers had been scrutinized, but the thieves, or spies, left empty-handed. He said that there was no danger that his invention could be stolen, for he had at no time committed any part of it to paper; the blueprint for the teleforce weapon was all in his mind.\n",
      "Quesiton According to Tesla what had been gone over by the thieves, or spies who entered his room?\n",
      "True Answer ['his papers'] | Predicted Answer: papers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test model answers\n",
    "test_samples = 10\n",
    "for i in range(test_samples):\n",
    "    random_example = np.random.randint(0, len(validation_features['example_id']))\n",
    "    example = dataset[\"validation\"][random_example]\n",
    "    predicted_answer = final_predictions[example['id']]\n",
    "    print(f\"example ID: {example['id']}\")\n",
    "    print(f\"Context: {example['context']}\")\n",
    "    print(f\"Quesiton {example['question']}\")\n",
    "    print(f\"True Answer {example['answers']['text']} | Predicted Answer: {predicted_answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e23cf2-cdf8-4bca-8644-31e8f2d62a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f371500-2f59-44e5-9312-d82eed6ecedd",
   "metadata": {},
   "source": [
    "selanjutnya dilakukan hyperparameter tuning dengan mengubah parameter sebagai berikut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e075034d-0915-4eb3-81ac-b17ebdf3109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "num_train_epochs = 2\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ffd4d4a1-3fda-4b99-bfd5-662564bbca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to tensor flow dataset to ffeed into model\n",
    "train_set = model.prepare_tf_dataset(\n",
    "    train_val_set[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "validation_set = model.prepare_tf_dataset(\n",
    "    train_val_set[\"validation\"],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87efba13-9fc4-4073-b613-7cc9813c2666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5545/5545 [==============================] - 83543s 15s/step - loss: 0.2928 - end_logits_accuracy: 0.9112 - start_logits_accuracy: 0.8861 - val_loss: 1.4965 - val_end_logits_accuracy: 0.6992 - val_start_logits_accuracy: 0.6598\n",
      "Epoch 2/2\n",
      "5545/5545 [==============================] - 57692s 10s/step - loss: 0.1792 - end_logits_accuracy: 0.9460 - start_logits_accuracy: 0.9301 - val_loss: 1.7272 - val_end_logits_accuracy: 0.6988 - val_start_logits_accuracy: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x1b7004f1510>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "total_train_steps = len(train_set) * num_train_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "     init_lr=learning_rate,\n",
    "     num_warmup_steps=0,\n",
    "     num_train_steps=total_train_steps,\n",
    "     weight_decay_rate= weight_decay\n",
    " )\n",
    "\n",
    "model.compile(optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "     train_set,\n",
    "     validation_data=validation_set,\n",
    "     epochs=num_train_epochs\n",
    "    #     callbacks = callbacks\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8991cbd-ddaa-4087-9af6-e65506004e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 1482s 2s/step - loss: 1.7272 - end_logits_accuracy: 0.6988 - start_logits_accuracy: 0.6656\n"
     ]
    }
   ],
   "source": [
    "eval_loss = model.evaluate(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c90e632-d004-4471-ad96-4596b2d7a6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 64.22894985808892, 'f1': 79.11440805987684}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_predictions = [\n",
    "    {\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()\n",
    "]\n",
    "references = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in dataset[\"validation\"]\n",
    "]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9dcc745-96e8-422f-a31e-510b2da0e6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 10570 example predictions split into 10822 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488f24e6ad764590bfa1676fc608447c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(\n",
    "    dataset[\"validation\"],\n",
    "    validation_features,\n",
    "    raw_predictions[\"start_logits\"],\n",
    "    raw_predictions[\"end_logits\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6406f61d-74cb-409b-b390-287981cd14ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example ID: 57113639a58dae1900cd6d1a\n",
      "Context: It is a logical extension of the compound engine (described above) to split the expansion into yet more stages to increase efficiency. The result is the multiple expansion engine. Such engines use either three or four expansion stages and are known as triple and quadruple expansion engines respectively. These engines use a series of cylinders of progressively increasing diameter. These cylinders are designed to divide the work into equal shares for each expansion stage. As with the double expansion engine, if space is at a premium, then two smaller cylinders may be used for the low-pressure stage. Multiple expansion engines typically had the cylinders arranged inline, but various other formations were used. In the late 19th century, the Yarrow-Schlick-Tweedy balancing 'system' was used on some marine triple expansion engines. Y-S-T engines divided the low-pressure expansion stages between two cylinders, one at each end of the engine. This allowed the crankshaft to be better balanced, resulting in a smoother, faster-responding engine which ran with less vibration. This made the 4-cylinder triple-expansion engine popular with large passenger liners (such as the Olympic class), but this was ultimately replaced by the virtually vibration-free turbine engine.[citation needed]\n",
      "Quesiton In what century was the Yarrow-Schlick-Tweedy balancing system used?\n",
      "True Answer ['19th'] | Predicted Answer: 19th\n",
      "\n",
      "example ID: 56d2045de7d4791d009025f3\n",
      "Context: The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.\n",
      "Quesiton Who is the quarterback for the Panthers?\n",
      "True Answer ['Cam Newton'] | Predicted Answer: Cam Newton\n",
      "\n",
      "example ID: 572961f61d0469140077935b\n",
      "Context: While primary chloroplasts have a double membrane from their cyanobacterial ancestor, secondary chloroplasts have additional membranes outside of the original two, as a result of the secondary endosymbiotic event, when a nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it—much like the cyanobacterium at the beginning of this story. The engulfed alga was broken down, leaving only its chloroplast, and sometimes its cell membrane and nucleus, forming a chloroplast with three or four membranes—the two cyanobacterial membranes, sometimes the eaten alga's cell membrane, and the phagosomal vacuole from the host's cell membrane.\n",
      "Quesiton What was the secondary endosymbiotic event?\n",
      "True Answer ['a nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it'] | Predicted Answer: a nonphotosynthetic eukaryote engulfed a chloroplast-containing alga but failed to digest it\n",
      "\n",
      "example ID: 57296cb21d04691400779406\n",
      "Context: In land plants, chloroplasts are generally lens-shaped, 5–8 μm in diameter and 1–3 μm thick. Greater diversity in chloroplast shapes exists among the algae, which often contain a single chloroplast that can be shaped like a net (e.g., Oedogonium), a cup (e.g., Chlamydomonas), a ribbon-like spiral around the edges of the cell (e.g., Spirogyra), or slightly twisted bands at the cell edges (e.g., Sirogonium). Some algae have two chloroplasts in each cell; they are star-shaped in Zygnema, or may follow the shape of half the cell in order Desmidiales. In some algae, the chloroplast takes up most of the cell, with pockets for the nucleus and other organelles (for example some species of Chlorella have a cup-shaped chloroplast that occupies much of the cell).\n",
      "Quesiton What shape is Oedogonium's chloroplasts?\n",
      "True Answer ['a net'] | Predicted Answer: a net\n",
      "\n",
      "example ID: 57287ccb2ca10214002da3de\n",
      "Context: The Yuan dynasty was the first time that non-native Chinese people ruled all of China. In the historiography of Mongolia, it is generally considered to be the continuation of the Mongol Empire. Mongols are widely known to worship the Eternal Heaven, and according to the traditional Mongolian ideology Yuan is considered to be \"the beginning of an infinite number of beings, the foundation of peace and happiness, state power, the dream of many peoples, besides it there is nothing great or precious.\" In traditional historiography of China, on the other hand, the Yuan dynasty is usually considered to be the legitimate dynasty between the Song dynasty and the Ming dynasty. Note, however, Yuan dynasty is traditionally often extended to cover the Mongol Empire before Kublai Khan's formal establishment of the Yuan in 1271, partly because Kublai had his grandfather Genghis Khan placed on the official record as the founder of the dynasty or Taizu (Chinese: 太祖). Despite the traditional historiography as well as the official views (including the government of the Ming dynasty which overthrew the Yuan dynasty), there also exist Chinese people[who?] who did not consider the Yuan dynasty as a legitimate dynasty of China, but rather as a period of foreign domination. The latter believe that Han Chinese were treated as second-class citizens,[citation needed] and that China stagnated economically and scientifically.\n",
      "Quesiton Some Chinese considered the Yuan a legitimate dynasty, but what did other Chinese think it was?\n",
      "True Answer ['a period of foreign domination'] | Predicted Answer: a period of foreign domination\n",
      "\n",
      "example ID: 57108d69b654c5140001f983\n",
      "Context: After the revocation of the Edict of Nantes, the Dutch Republic received the largest group of Huguenot refugees, an estimated total of 75,000 to 100,000 people. Amongst them were 200 clergy. Many came from the region of the Cévennes, for instance, the village of Fraissinet-de-Lozère. This was a huge influx as the entire population of the Dutch Republic amounted to ca. 2 million at that time. Around 1700, it is estimated that nearly 25% of the Amsterdam population was Huguenot.[citation needed] In 1705, Amsterdam and the area of West Frisia were the first areas to provide full citizens rights to Huguenot immigrants, followed by the Dutch Republic in 1715. Huguenots intermarried with Dutch from the outset.\n",
      "Quesiton What country initially received the largest number of Huguenot refugees?\n",
      "True Answer ['the Dutch Republic'] | Predicted Answer: the Dutch Republic\n",
      "\n",
      "example ID: 56e76c6a00c9c71400d77110\n",
      "Context: There are several ways to mitigate the occupational hazards of teaching. Organizational interventions, like changing teachers' schedules, providing support networks and mentoring, changing the work environment, and offering promotions and bonuses, may be effective in helping to reduce occupational stress among teachers. Individual-level interventions, including stress-management training and counseling, are also used to relieve occupational stress among teachers.\n",
      "Quesiton What is stress-management training considered to be?\n",
      "True Answer ['Individual-level interventions'] | Predicted Answer: relieve\n",
      "\n",
      "example ID: 573005b9947a6a140053cf6c\n",
      "Context: The quick and decisive defeat of the Arab troops during the Six-Day War by Israeli troops constituted a pivotal event in the Arab Muslim world. The defeat along with economic stagnation in the defeated countries, was blamed on the secular Arab nationalism of the ruling regimes. A steep and steady decline in the popularity and credibility of secular, socialist and nationalist politics ensued. Ba'athism, Arab socialism, and Arab nationalism suffered, and different democratic and anti-democratic Islamist movements inspired by Maududi and Sayyid Qutb gained ground.\n",
      "Quesiton Secular Arab nationalism was blamed for both the defeat of Arab troops as well as what type of stagnation?\n",
      "True Answer ['economic'] | Predicted Answer: secular\n",
      "\n",
      "example ID: 57378862c3c5551400e51f23\n",
      "Context: In this equation, a dimensional constant  is used to describe the relative strength of gravity. This constant has come to be known as Newton's Universal Gravitation Constant, though its value was unknown in Newton's lifetime. Not until 1798 was Henry Cavendish able to make the first measurement of  using a torsion balance; this was widely reported in the press as a measurement of the mass of the Earth since knowing  could allow one to solve for the Earth's mass given the above equation. Newton, however, realized that since all celestial bodies followed the same laws of motion, his law of gravity had to be universal. Succinctly stated, Newton's Law of Gravitation states that the force on a spherical object of mass  due to the gravitational pull of mass  is\n",
      "Quesiton When was the first measurement of the value of the Newton Universal Gravitation Constant?\n",
      "True Answer ['1798'] | Predicted Answer: 1798\n",
      "\n",
      "example ID: 56be54bdacb8001400a50325\n",
      "Context: The league announced on October 16, 2012, that the two finalists were Sun Life Stadium and Levi's Stadium. The South Florida/Miami area has previously hosted the event 10 times (tied for most with New Orleans), with the most recent one being Super Bowl XLIV in 2010. The San Francisco Bay Area last hosted in 1985 (Super Bowl XIX), held at Stanford Stadium in Stanford, California, won by the home team 49ers. The Miami bid depended on whether the stadium underwent renovations. However, on May 3, 2013, the Florida legislature refused to approve the funding plan to pay for the renovations, dealing a significant blow to Miami's chances.\n",
      "Quesiton When was the most recent Super Bowl hosted in the South Florida/Miami area?\n",
      "True Answer ['2010'] | Predicted Answer: 2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_samples = 10\n",
    "for i in range(test_samples):\n",
    "    random_example = np.random.randint(0, len(validation_features['example_id']))\n",
    "    example = dataset[\"validation\"][random_example]\n",
    "    predicted_answer = final_predictions[example['id']]\n",
    "    print(f\"example ID: {example['id']}\")\n",
    "    print(f\"Context: {example['context']}\")\n",
    "    print(f\"Quesiton {example['question']}\")\n",
    "    print(f\"True Answer {example['answers']['text']} | Predicted Answer: {predicted_answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca640f40-4716-4ef2-a241-c01f01ade52a",
   "metadata": {},
   "source": [
    "model bekerja dengan baik dalam memprediksi jawaban sesuai konteks yang diberikan. Selanjutnya dicoba untuk menggunakan tokenizer yang  berbeda, yaitu T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b043fde-b450-42c7-8b89-002e3a51f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd25a6b8-4327-4df5-a81f-da9d8ddcbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "MODEL = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True)\n",
    "OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n",
    "Q_LEN = 256   # Question Length\n",
    "T_LEN = 32    # Target Length\n",
    "# BATCH_SIZE = 4\n",
    "BATCH_SIZE = 10\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07903a67-c6bf-4d35-9655-099712fe564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "with open(r'C:\\\\Users\\\\PPL2\\\\Documents\\\\Private\\\\Model\\\\Pacman Data Science\\\\Project\\\\Natural Languange Processing/train-v1.1.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18137d66-70c4-4cc3-9dbc-7d9a8a269657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    articles = []\n",
    "    \n",
    "    for article in data[\"data\"]:\n",
    "        for paragraph in article[\"paragraphs\"]:\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answer = qa[\"answers\"][0][\"text\"]\n",
    "                inputs = {\"context\": paragraph[\"context\"], \"question\": question, \"answer\": answer}\n",
    "                articles.append(inputs)\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7584f937-0208-4ac4-8fd8-85287339f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(data)\n",
    "\n",
    "# Create a Dataframe\n",
    "data = pd.DataFrame(data)\n",
    "data = data.loc[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2cf22b44-ff06-48a0-9385-6e7c7f0a7031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3001, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba4b7493-82a1-4c31-b7a0-156d8ecd6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_Dataset(Dataset):\n",
    "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.q_len = q_len\n",
    "        self.t_len = t_len\n",
    "        self.data = dataframe\n",
    "        self.questions = self.data[\"question\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.answer = self.data['answer']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        context = self.context[idx]\n",
    "        answer = self.answer[idx]\n",
    "        \n",
    "        question_tokenized = self.tokenizer(question, context, max_length=self.q_len, padding=\"max_length\",\n",
    "                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\", \n",
    "                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        \n",
    "        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n",
    "            \"labels\": labels,\n",
    "            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb595ee4-8188-4a76-8d82-531d7ff225a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sampler = RandomSampler(train_data.index)\n",
    "val_sampler = RandomSampler(val_data.index)\n",
    "\n",
    "qa_dataset = QA_Dataset(TOKENIZER, data, Q_LEN, T_LEN)\n",
    "\n",
    "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed43956c-3ad4-447f-a3db-766d39e57ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL.to(DEVICE)\n",
    "OPTIMIZER = torch.optim.Adam(MODEL.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "80428eac-dc2d-4087-9231-80c196bd4b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00144bd186c0496ea6a79faeab2f7998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e2108f452c4100a689b681cf48b417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 -> Train loss: 2.493030342956384\tValidation loss: 1.435157461244552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bdefadceb0454a88fa8f8917f1b8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a707eca8c7ab47a89e9dc9bc27095b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 -> Train loss: 1.8402289805933834\tValidation loss: 1.0448074530749047\n"
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "train_batch_count = 0\n",
    "val_batch_count = 0\n",
    "\n",
    "for epoch in range(2):\n",
    "    MODEL.train()\n",
    "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=decoder_attention_mask\n",
    "        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        train_loss += outputs.loss.item()\n",
    "        train_batch_count += 1\n",
    "    \n",
    "    # Evaluation\n",
    "    MODEL.eval()\n",
    "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=decoder_attention_mask\n",
    "        )\n",
    "\n",
    "        val_loss += outputs.loss.item()\n",
    "        val_batch_count += 1\n",
    "\n",
    "    print(f\"{epoch+1}/{2} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "deed1fc3-e506-4354-baa9-0fa52be293b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('qa_tokenizer/tokenizer_config.json',\\n 'qa_tokenizer/special_tokens_map.json',\\n 'qa_tokenizer/spiece.model',\\n'qa_tokenizer/added_tokens.json',\\n'qa_tokenizer/tokenizer.json')\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.save_pretrained(\"qa_model\")\n",
    "TOKENIZER.save_pretrained(\"qa_tokenizer\")\n",
    "\n",
    "# Saved files\n",
    "\"\"\"('qa_tokenizer/tokenizer_config.json',\n",
    " 'qa_tokenizer/special_tokens_map.json',\n",
    " 'qa_tokenizer/spiece.model',\n",
    "'qa_tokenizer/added_tokens.json',\n",
    "'qa_tokenizer/tokenizer.json')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87c0ceee-6452-4cb1-b903-41a7253bd289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(context, question, ref_answer=None):\n",
    "    inputs = TOKENIZER(question, context, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
    "    \n",
    "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "  \n",
    "    predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n",
    "    \n",
    "    if ref_answer:\n",
    "        bleu = evaluate.load(\"google_bleu\")\n",
    "        print(predicted_answer, ref_answer)\n",
    "        score = bleu.compute(predictions=[predicted_answer], references=[ref_answer])\n",
    "    \n",
    "        print(\"Context: \\n\", context)\n",
    "        print(\"\\n\")\n",
    "        print(\"Question: \\n\", question)\n",
    "        return {\n",
    "            \"Reference Answer: \": ref_answer, \n",
    "            \"Predicted Answer: \": predicted_answer, \n",
    "            \"BLEU Score: \": score\n",
    "        }\n",
    "    else:\n",
    "        return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "717ddbf2-0814-4a85-9368-6f5cd4bc7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = data.iloc[0][\"context\"]\n",
    "question = data.iloc[0][\"question\"]\n",
    "answer = data.iloc[0][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a3e6214-aa43-4fb4-9ff4-df335ea0335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PPL2\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saint Bernadette Soubirous Saint Bernadette Soubirous\n",
      "Context: \n",
      " Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "\n",
      "\n",
      "Question: \n",
      " To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Reference Answer: ': 'Saint Bernadette Soubirous',\n",
       " 'Predicted Answer: ': 'Saint Bernadette Soubirous',\n",
       " 'BLEU Score: ': {'google_bleu': 1.0}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_answer(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba2b6217-ee9c-437c-921a-c70cbc65875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Virat Kohli on Tuesday slammed his 73rd international hundred by reaching the three-figure mark off 80 deliveries against Sri Lanka in first ODI in Guwahati. \n",
    "The 34-year-old became the fastest batter to slam 20 ODI hundreds on Indian soil, taking 99 innings. \n",
    "He also overtook Sachin Tendulkar to become the fastest batter to smash 45 ODI hundreds, taking 257 innings.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "29164bc9-7f67-40cd-9980-919fa3464934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'257'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_1=\"How many innings does Virat Kohli took to reach 45 ODI hundreds?\" \n",
    "predict_answer(context, q_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbacb77d-03d2-4243-bbb0-b1357eb66f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
